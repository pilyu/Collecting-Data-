{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88ca64e0-cea5-42aa-ac6e-058c87fad9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lorga\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package cess_esp to\n",
      "[nltk_data]     C:\\Users\\lorga\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\cess_esp.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from glob import glob\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"cess_esp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1d7d192-7b4f-4307-b226-14251315664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura de un archivo\n",
    "def read_file(filename):\n",
    "    with open(filename, encoding='utf8') as infile:\n",
    "        contents = infile.read()\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31beabb1-5ba0-4ccf-ae72-f5a2709646c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algunas palabras se rompen en letras individuales y esta función trata de recomponer las palbras\n",
    "def retokenize(tokenized_text):\n",
    "    tokenized = []\n",
    "    is_broken_word = False\n",
    "    temp_word = \"\"\n",
    "    for token in tokenized_text:\n",
    "        if len(token) == 1:\n",
    "            if not is_broken_word:\n",
    "                is_broken_word = True\n",
    "                temp_word = token\n",
    "            else:\n",
    "                temp_word += token\n",
    "        else:\n",
    "            if is_broken_word:\n",
    "                tokenized.append(temp_word)\n",
    "                temp_word = \"\"\n",
    "                is_broken_word = False\n",
    "            tokenized.append(token)\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cca38cdd-414d-4657-9619-97f62bad41b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crear un corpus con los textos tokenizados\n",
    "# Read and tokenize the input file\n",
    "# Fix broken words\n",
    "# Remove tokens not found in Spanish corpus. Spanish_corpus como variable lo que hace es tomar el corpus emina los duplicados\n",
    "#para obtener un listado de palabras en español. Esta linea define un set, ya que esto evita los duplicados. Para las comparaciones no nos sirven los duplicados.\n",
    "#Elimina todas las palabras que no existen dentro del corpus en español. Esta línea define una lista, la lista si permite duplicados, ya que esto nos permite hacer el ánalisis de cuánto se usa una palabra por ejemplo.\n",
    "\n",
    "spanish_corpus = {word.lower() for word in nltk.corpus.cess_esp.words()}\n",
    "\n",
    "for filename in glob('texts/*.txt'):\n",
    "    text = read_file(filename)\n",
    "    tokenized_text = nltk.tokenize.word_tokenize(text)\n",
    "    tokenized_text = retokenize(tokenized_text)\n",
    "    clean_texts = [word for word in tokenized_text if word in spanish_corpus]\n",
    "    with open(f'clean_{filename}', 'w', encoding = 'utf-8') as fp:\n",
    "        for item in clean_texts:\n",
    "            fp.write(f'{item} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b905c37c-6b38-4150-9251-9bc030b02f39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
